PREPARACION DE DATOS

	1- PREPARANDO ARCHIVO
	A- ponemos titulo a cada columna del archivo .csv Age,Sex,Blood_Pressure,Cholesterol,Na,K,Drug
	B- mostramos histograma de los datos (descripcion de los datos)

	2- LIMPIEZA DE DATOS
	A- datos ausentes/nulos, datos atipicos, registros duplicados
		How To Handle Missing Values In Machine Learning Data With Weka
			- How to mark missing values in your dataset.
				You can mark missing values in Weka using the unsupervized/attribute/NumericalCleaner filter
					Esta configuracion nos permite marcar "edades" atipicas en el dataset
						attributeIndices: 1 // apply to attribute with index 1 (age)
						maxThreshoold: 110 // max age allowed
						maxDefault: NaN
						minThreshoold: 0 // min age allowed
						minDefault: NaN
					[mostrar imagen1]
					solo se detecta un dato atipico: que representa el 1% de los datos (edad de 145 años)

					Esta configuracion nos permite marcar "niveles de Na" atipicos en el dataset
						attributeIndices: 5 // apply to attribute with index 5 (Na)
						maxThreshoold: 1 // max age allowed
						maxDefault: NaN
						minThreshoold: 0 // min age allowed
						minDefault: NaN


			- How to remove data(instances) with missing values from your dataset.
				You can do this in Weka using the unsupervized/instance/RemoveWithValues filter. 
				(in R: https://stackoverflow.com/questions/8005154/conditionally-remove-dataframe-rows-with-r)
				
				esta configuracion nos permite eliminar missing instances en el dataset
					attributeIndices: 1 // apply to attribute with index 1 (age)
					matchMissingValues: True // missing values count as a match
					splitPoint: -1 // numeric values to be used for selection on numeric attribute


			- How to impute missing values.
				Instances with missing values do not have to be removed, you can replace the missing values with some other value. This is called imputing missing values.

				It is common to impute missing values with the mean of the numerical distribution. You can do this easily in Weka using the unsupervized/attribute/ReplaceMissingValues filter.

			- How to remove duplicate rows(register or instances)
				unsupervized/instance/RemoveDuplicates filter

	3- TRANSFORMACION DE LOS DATOS
	A- Normalización, discretización y conversión categórica a numérica (automática en weka)

		- When and why do we need data normalization?
			if you're counting the frequency of occurrence of the same phenomena in two different population with different size and you want to compare them, you have to normalize both, because otherwise you do not know how big the influence of your phenomena is in relation to the total number of cases. Thus, normalization is needed, when comparing populations/phenomena of different size but with the same origin.


		- How to normalize data in weka?
			unsupervised/attribute/Normalize filter

			Normalizes all numeric values in the given dataset
			(apart from the class attribute, if set).

		- How to discretize an attribute?
			unsupervised/attribute/discretize filter

			attributeIndices: 3,4
			bins: 6

	4- REDUCCION DE VARIABLES
	A- PCA (attributes/Principal components analysis)

		- how to use PCA in weka?
			ir a la pestaña: "select attributes"

			poner "attribute evaluator" como "PrincipalComponents"
				transformBackToOriginalSpace: True

			poner "search method" como "ranker"

			el resultado obtenido es:

			Ranked attributes:
			 1   8 K
			 1   7 Na
			 1   2 Sex=M
			 1   3 Blood_Pressure=HIGH
			 1   4 Blood_Pressure=LOW
			 1   5 Blood_Pressure=NORMAL
			 1   6 Cholesterol=NORMAL
			 1   1 Age

			Selected attributes: 8,7,2,3,4,5,6,1 : 8

			borrar el attribute "age" pues es irrelevante segun el PCA

			==================================================================

			ejecutando un segundo PCA se obtiene que el sex es irrelevante,
			por eso removeremos el attributo sexo (columna)

			Ranked attributes:
			 1   7 K
			 1   3 Blood_Pressure=LOW
			 1   2 Blood_Pressure=HIGH
			 1   4 Blood_Pressure=NORMAL
			 1   6 Na
			 1   5 Cholesterol=NORMAL
			 1   1 Sex=M

			Selected attributes: 7,3,2,4,6,5,1 : 7

	5- BALANCEO DE DATOS:
	A- Balanceo de la variable a predecir

	supervised/instance/SMOTE filter

		lassValue: 0
		percentage: 100.0

APLICANDO METODOS

	1- METODOS DE REGRESION
		can´t apply this method because we hava a classification problem, no a regression problem
		es decir, estamos intentando predecir un valor nominal y no un valor numerico
		ref: https://www.youtube.com/watch?v=6tDnNyNZDF0

	2- ARBOLES DE DECISION
		J48 trees
		ref: https://www.youtube.com/watch?v=l7R9NHqvI0Y

		J48 pruned tree
		------------------

		Blood_Pressure = HIGH
		|   K = '(-inf-0.166667]': drugY (18.0)
		|   K = '(0.166667-0.333333]': drugY (10.0/1.0)
		|   K = '(0.333333-0.5]': drugY (12.0/5.0)
		|   K = '(0.5-0.666667]'
		|   |   Na = '(-inf-0.166667]': drugA (2.0)
		|   |   Na = '(0.166667-0.333333]': drugB (1.0)
		|   |   Na = '(0.333333-0.5]': drugB (4.0/1.0)
		|   |   Na = '(0.5-0.666667]': drugB (0.0)
		|   |   Na = '(0.666667-0.833333]': drugB (3.0/1.0)
		|   |   Na = '(0.833333-inf)': drugY (3.0)
		|   K = '(0.666667-0.833333]': drugA (12.0/3.0)
		|   K = '(0.833333-inf)': drugB (11.0/5.0)
		Blood_Pressure = LOW
		|   Cholesterol = HIGH
		|   |   K = '(-inf-0.166667]': drugY (3.0)
		|   |   K = '(0.166667-0.333333]': drugY (6.0)
		|   |   K = '(0.333333-0.5]': drugY (4.0/1.0)
		|   |   K = '(0.5-0.666667]': drugC (10.0/3.0)
		|   |   K = '(0.666667-0.833333]': drugC (12.0)
		|   |   K = '(0.833333-inf)': drugC (12.0)
		|   Cholesterol = NORMAL
		|   |   K = '(-inf-0.166667]': drugY (10.0)
		|   |   K = '(0.166667-0.333333]': drugY (4.0/1.0)
		|   |   K = '(0.333333-0.5]': drugY (4.0/2.0)
		|   |   K = '(0.5-0.666667]': drugX (3.0)
		|   |   K = '(0.666667-0.833333]': drugX (8.0)
		|   |   K = '(0.833333-inf)': drugX (4.0)
		Blood_Pressure = NORMAL
		|   K = '(-inf-0.166667]': drugY (6.0)
		|   K = '(0.166667-0.333333]': drugY (7.0)
		|   K = '(0.333333-0.5]'
		|   |   Na = '(-inf-0.166667]': drugX (3.0)
		|   |   Na = '(0.166667-0.333333]': drugX (3.0)
		|   |   Na = '(0.333333-0.5]': drugX (1.0)
		|   |   Na = '(0.5-0.666667]': drugY (3.0)
		|   |   Na = '(0.666667-0.833333]': drugY (4.0)
		|   |   Na = '(0.833333-inf)': drugY (2.0)
		|   K = '(0.5-0.666667]': drugX (7.0/1.0)
		|   K = '(0.666667-0.833333]': drugX (8.0)
		|   K = '(0.833333-inf)': drugX (15.0)

		Number of Leaves  : 	34

		Size of the tree : 	42


		Time taken to build model: 0.02 seconds

		=== Stratified cross-validation ===
		=== Summary ===

		Correctly Classified Instances         182               84.6512 %
		Incorrectly Classified Instances        33               15.3488 %
		Kappa statistic                          0.784 
		Mean absolute error                      0.0699
		Root mean squared error                  0.2102
		Relative absolute error                 24.199  %
		Root relative squared error             55.3923 %
		Total Number of Instances              215     

		=== Detailed Accuracy By Class ===

		                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
		                 0,923    0,105    0,866      0,923    0,894      0,812    0,950     0,922     drugY
		                 0,969    0,016    0,912      0,969    0,939      0,929    0,980     0,953     drugC
		                 0,926    0,019    0,943      0,926    0,935      0,913    0,980     0,924     drugX
		                 0,500    0,036    0,611      0,500    0,550      0,507    0,912     0,610     drugA
		                 0,375    0,035    0,462      0,375    0,414      0,374    0,927     0,468     drugB
		Weighted Avg.    0,847    0,058    0,836      0,847    0,840      0,791    0,956     0,862     

		=== Confusion Matrix ===

		  a  b  c  d  e   <-- classified as
		 84  3  3  0  1 |  a = drugY
		  1 31  0  0  0 |  b = drugC
		  4  0 50  0  0 |  c = drugX
		  5  0  0 11  6 |  d = drugA
		  3  0  0  7  6 |  e = drugB